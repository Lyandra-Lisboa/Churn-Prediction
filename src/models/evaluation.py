"""
Avalia√ß√£o do modelo K-Modes - Ligga
"""
import os
import joblib
import logging
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import silhouette_score, adjusted_rand_score
from sklearn.preprocessing import LabelEncoder
from sqlalchemy import create_engine
from config_ligga import PostgreSQLConfig, TableConfig

# Configura√ß√£o de logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

MODEL_PATH = "models/kmodes_churn_ligga.pkl"
DATA_PATH = "models/processed_data_ligga.csv"
REPORTS_DIR = "reports"

class LiggaModelEvaluator:
    """
    Classe para avalia√ß√£o completa do modelo de clusteriza√ß√£o da Ligga
    """
    
    def __init__(self):
        self.model = None
        self.data = None
        self.processed_data = None
        self.clusters = None
        self.db_config = PostgreSQLConfig()
        self.table_config = TableConfig()
        
        # Personas info
        self.personas_info = {
            0: {"nome": "Recente Negativo", "risco": "ALTO"},
            1: {"nome": "Recente Positivo", "risco": "BAIXO"},
            2: {"nome": "Alto Valor N√£o Fidelizado", "risco": "M√âDIO-ALTO"},
            3: {"nome": "Alto Valor Fidelizado", "risco": "BAIXO"},
            4: {"nome": "Padr√£o Capital", "risco": "M√âDIO"},
            5: {"nome": "Baixo Valor Negativo", "risco": "ALTO"},
            6: {"nome": "Baixo Valor Positivo", "risco": "BAIXO"},
            7: {"nome": "Interior N√£o Fidelizado", "risco": "M√âDIO"},
            8: {"nome": "Interior Fidelizado", "risco": "BAIXO"},
            9: {"nome": "Baixa Velocidade", "risco": "M√âDIO"}
        }
        
        os.makedirs(REPORTS_DIR, exist_ok=True)
    
    def load_model_and_data(self):
        """
        Carrega modelo treinado e dados processados
        """
        if not os.path.exists(MODEL_PATH):
            raise FileNotFoundError(f"Modelo n√£o encontrado em {MODEL_PATH}. Execute training.py primeiro.")
        
        if not os.path.exists(DATA_PATH):
            raise FileNotFoundError(f"Dados processados n√£o encontrados em {DATA_PATH}. Execute training.py primeiro.")
        
        # Carregar modelo
        self.model = joblib.load(MODEL_PATH)
        logging.info("Modelo carregado com sucesso")
        
        # Carregar dados processados
        self.processed_data = pd.read_csv(DATA_PATH)
        logging.info(f"Dados processados carregados: {len(self.processed_data)} registros")
        
        # Extrair features e clusters
        feature_cols = [
            'faixa_valor', 'faixa_aging', 'regiao', 'faixa_velocidade',
            'perfil_atendimento', 'is_churner', 'cliente_tipo',
            'faixa_vencimento', 'tipo_produto', 'canal_produto'
        ]
        
        self.data = self.processed_data[feature_cols].copy()
        self.clusters = self.processed_data['cluster'].values
        
        return True
    
    def calculate_silhouette_score(self):
        """
        Calcula Silhouette Score para avalia√ß√£o da qualidade dos clusters
        """
        logging.info("Calculando Silhouette Score...")
        
        # Converter dados categ√≥ricos para num√©ricos
        data_encoded = self.data.copy()
        encoders = {}
        
        for col in data_encoded.columns:
            le = LabelEncoder()
            data_encoded[col] = le.fit_transform(data_encoded[col].astype(str))
            encoders[col] = le
        
        # Calcular silhouette score
        score = silhouette_score(data_encoded, self.clusters, metric='euclidean')
        logging.info(f"Silhouette Score: {score:.4f}")
        
        return score, encoders
    
    def analyze_cluster_characteristics(self):
        """
        Analisa caracter√≠sticas detalhadas de cada cluster
        """
        logging.info("Analisando caracter√≠sticas dos clusters...")
        
        cluster_analysis = {}
        
        for cluster_id in sorted(self.processed_data['cluster'].unique()):
            cluster_data = self.processed_data[self.processed_data['cluster'] == cluster_id]
            
            analysis = {
                'tamanho': len(cluster_data),
                'percentual': (len(cluster_data) / len(self.processed_data)) * 100,
                'valor_medio': cluster_data['valor_contrato'].mean(),
                'valor_mediano': cluster_data['valor_contrato'].median(),
                'aging_medio': cluster_data['aging_meses'].mean(),
                'churn_rate': (cluster_data['is_churner'] != 'ativo').mean() * 100,
                'atendimentos_medio': cluster_data['total_atendimentos'].mean(),
                'regiao_predominante': cluster_data['regiao'].mode().iloc[0] if len(cluster_data) > 0 else 'N/A',
                'velocidade_media': cluster_data['velocidade_num'].mean(),
                'score_serasa_info': self._get_score_info(cluster_data)
            }
            
            cluster_analysis[cluster_id] = analysis
        
        return cluster_analysis
    
    def _get_score_info(self, cluster_data):
        """
        Calcula informa√ß√µes de score baseadas nas caracter√≠sticas do cluster
        """
        # Simular score baseado nas caracter√≠sticas (como na an√°lise original)
        valor_medio = cluster_data['valor_contrato'].mean()
        churn_rate = (cluster_data['is_churner'] != 'ativo').mean()
        atendimentos = cluster_data['total_atendimentos'].mean()
        
        # Score estimado baseado nas caracter√≠sticas
        score_estimado = 800 - (churn_rate * 400) - (atendimentos * 20) + (valor_medio * 2)
        score_estimado = max(300, min(900, score_estimado))  # Limitar entre 300-900
        
        return {
            'score_estimado': score_estimado,
            'qualidade': 'Alto' if score_estimado > 700 else 'M√©dio' if score_estimado > 500 else 'Baixo'
        }
    
    def analyze_business_metrics(self):
        """
        An√°lise de m√©tricas de neg√≥cio espec√≠ficas da Ligga
        """
        logging.info("Analisando m√©tricas de neg√≥cio...")
        
        business_metrics = {}
        
        # 1. Distribui√ß√£o de risco
        risk_distribution = {}
        for cluster_id, info in self.personas_info.items():
            if cluster_id in self.processed_data['cluster'].values:
                count = len(self.processed_data[self.processed_data['cluster'] == cluster_id])
                risk_level = info['risco']
                if risk_level not in risk_distribution:
                    risk_distribution[risk_level] = 0
                risk_distribution[risk_level] += count
        
        business_metrics['distribuicao_risco'] = risk_distribution
        
        # 2. Valor m√©dio por cluster
        value_by_cluster = self.processed_data.groupby('cluster')['valor_contrato'].agg(['mean', 'median', 'std']).round(2)
        business_metrics['valor_por_cluster'] = value_by_cluster
        
        # 3. Taxa de churn por cluster
        churn_by_cluster = self.processed_data.groupby('cluster').apply(
            lambda x: (x['is_churner'] != 'ativo').mean() * 100
        ).round(2)
        business_metrics['churn_por_cluster'] = churn_by_cluster
        
        # 4. Distribui√ß√£o geogr√°fica
        geo_distribution = pd.crosstab(self.processed_data['cluster'], self.processed_data['regiao'], normalize='index') * 100
        business_metrics['distribuicao_geografica'] = geo_distribution
        
        # 5. Qualidade de atendimento
        atendimento_quality = self.processed_data.groupby('cluster').agg({
            'total_atendimentos': 'mean',
            'atendimentos_negativos': 'mean',
            'atendimentos_resolvidos': 'mean'
        }).round(2)
        business_metrics['qualidade_atendimento'] = atendimento_quality
        
        return business_metrics
    
    def generate_cluster_comparison(self):
        """
        Gera compara√ß√£o detalhada entre clusters
        """
        logging.info("Gerando compara√ß√£o entre clusters...")
        
        comparison = []
        
        for cluster_id in sorted(self.processed_data['cluster'].unique()):
            cluster_data = self.processed_data[self.processed_data['cluster'] == cluster_id]
            persona = self.personas_info.get(cluster_id, {'nome': f'Cluster {cluster_id}', 'risco': 'N/A'})
            
            row = {
                'Cluster': cluster_id,
                'Persona': persona['nome'],
                'Risco': persona['risco'],
                'Quantidade': len(cluster_data),
                'Percentual': f"{(len(cluster_data) / len(self.processed_data)) * 100:.1f}%",
                'Valor M√©dio': f"R$ {cluster_data['valor_contrato'].mean():.2f}",
                'Aging M√©dio (meses)': f"{cluster_data['aging_meses'].mean():.1f}",
                'Taxa Churn': f"{(cluster_data['is_churner'] != 'ativo').mean() * 100:.1f}%",
                'Atendimentos M√©dio': f"{cluster_data['total_atendimentos'].mean():.1f}",
                'Regi√£o Principal': cluster_data['regiao'].mode().iloc[0] if len(cluster_data) > 0 else 'N/A'
            }
            
            comparison.append(row)
        
        comparison_df = pd.DataFrame(comparison)
        return comparison_df
    
    def evaluate_model_stability(self):
        """
        Avalia estabilidade do modelo com re-treinamento
        """
        logging.info("Avaliando estabilidade do modelo...")
        
        # Fazer predi√ß√µes novamente
        predictions = self.model.predict(self.data)
        
        # Comparar com clusters originais
        stability_score = adjusted_rand_score(self.clusters, predictions)
        
        # An√°lise de consist√™ncia
        consistency = (self.clusters == predictions).mean() * 100
        
        logging.info(f"Adjusted Rand Score: {stability_score:.4f}")
        logging.info(f"Consist√™ncia das predi√ß√µes: {consistency:.1f}%")
        
        return stability_score, consistency
    
    def generate_report(self):
        """
        Gera relat√≥rio completo de avalia√ß√£o
        """
        logging.info("=== INICIANDO AVALIA√á√ÉO COMPLETA DO MODELO ===")
        
        # Carregar dados
        self.load_model_and_data()
        
        # M√©tricas t√©cnicas
        silhouette, encoders = self.calculate_silhouette_score()
        stability, consistency = self.evaluate_model_stability()
        
        # An√°lises de neg√≥cio
        cluster_chars = self.analyze_cluster_characteristics()
        business_metrics = self.analyze_business_metrics()
        comparison_df = self.generate_cluster_comparison()
        
        # Relat√≥rio no console
        logging.info("\n" + "="*60)
        logging.info("RELAT√ìRIO DE AVALIA√á√ÉO DO MODELO LIGGA")
        logging.info("="*60)
        
        logging.info(f"\nüìä M√âTRICAS T√âCNICAS:")
        logging.info(f"  ‚Ä¢ Silhouette Score: {silhouette:.4f}")
        logging.info(f"  ‚Ä¢ Estabilidade (ARI): {stability:.4f}")
        logging.info(f"  ‚Ä¢ Consist√™ncia: {consistency:.1f}%")
        
        logging.info(f"\nüìà DISTRIBUI√á√ÉO DOS CLUSTERS:")
        cluster_dist = self.processed_data['cluster'].value_counts().sort_index()
        for cluster_id, count in cluster_dist.items():
            persona = self.personas_info.get(cluster_id, {'nome': f'Cluster {cluster_id}'})
            pct = (count / len(self.processed_data)) * 100
            logging.info(f"  ‚Ä¢ Cluster {cluster_id} ({persona['nome']}): {count} clientes ({pct:.1f}%)")
        
        logging.info(f"\n‚ö†Ô∏è  AN√ÅLISE DE RISCO:")
        for risk, count in business_metrics['distribuicao_risco'].items():
            pct = (count / len(self.processed_data)) * 100
            logging.info(f"  ‚Ä¢ {risk}: {count} clientes ({pct:.1f}%)")
        
        logging.info(f"\nüí∞ TOP 3 CLUSTERS POR VALOR:")
        top_value = business_metrics['valor_por_cluster'].sort_values('mean', ascending=False).head(3)
        for cluster_id, row in top_value.iterrows():
            persona = self.personas_info.get(cluster_id, {'nome': f'Cluster {cluster_id}'})
            logging.info(f"  ‚Ä¢ {persona['nome']}: R$ {row['mean']:.2f} (m√©dio)")
        
        logging.info(f"\nüö® TOP 3 CLUSTERS POR RISCO DE CHURN:")
        top_churn = business_metrics['churn_por_cluster'].sort_values(ascending=False).head(3)
        for cluster_id, churn_rate in top_churn.items():
            persona = self.personas_info.get(cluster_id, {'nome': f'Cluster {cluster_id}'})
            logging.info(f"  ‚Ä¢ {persona['nome']}: {churn_rate:.1f}% de churn")
        
        # Salvar relat√≥rios detalhados
        self._save_detailed_reports(comparison_df, business_metrics, cluster_chars)
        
        logging.info(f"\nüìÅ Relat√≥rios detalhados salvos em: {REPORTS_DIR}/")
        logging.info("="*60)
        
        return {
            'silhouette_score': silhouette,
            'stability_score': stability,
            'consistency': consistency,
            'cluster_analysis': cluster_chars,
            'business_metrics': business_metrics,
            'comparison': comparison_df
        }
    
    def _save_detailed_reports(self, comparison_df, business_metrics, cluster_chars):
        """
        Salva relat√≥rios detalhados em arquivos
        """
        # 1. Compara√ß√£o de clusters
        comparison_df.to_csv(f"{REPORTS_DIR}/cluster_comparison.csv", index=False)
        
        # 2. M√©tricas de valor
        business_metrics['valor_por_cluster'].to_csv(f"{REPORTS_DIR}/valor_por_cluster.csv")
        
        # 3. Taxa de churn
        pd.DataFrame(business_metrics['churn_por_cluster']).to_csv(f"{REPORTS_DIR}/churn_por_cluster.csv")
        
        # 4. Distribui√ß√£o geogr√°fica
        business_metrics['distribuicao_geografica'].to_csv(f"{REPORTS_DIR}/distribuicao_geografica.csv")
        
        # 5. Relat√≥rio consolidado
        with open(f"{REPORTS_DIR}/relatorio_consolidado.txt", 'w', encoding='utf-8') as f:
            f.write("RELAT√ìRIO DE AVALIA√á√ÉO - MODELO LIGGA\n")
            f.write("="*50 + "\n\n")
            
            f.write("CARACTER√çSTICAS POR CLUSTER:\n")
            f.write("-"*30 + "\n")
            for cluster_id, chars in cluster_chars.items():
                persona = self.personas_info.get(cluster_id, {'nome': f'Cluster {cluster_id}', 'risco': 'N/A'})
                f.write(f"\nCluster {cluster_id} - {persona['nome']}:\n")
                f.write(f"  ‚Ä¢ Tamanho: {chars['tamanho']} clientes ({chars['percentual']:.1f}%)\n")
                f.write(f"  ‚Ä¢ Valor m√©dio: R$ {chars['valor_medio']:.2f}\n")
                f.write(f"  ‚Ä¢ Aging m√©dio: {chars['aging_medio']:.1f} meses\n")
                f.write(f"  ‚Ä¢ Taxa de churn: {chars['churn_rate']:.1f}%\n")
                f.write(f"  ‚Ä¢ Regi√£o predominante: {chars['regiao_predominante']}\n")
                f.write(f"  ‚Ä¢ Risco: {persona['risco']}\n")
        
        logging.info("Relat√≥rios detalhados salvos com sucesso")

def main():
    """
    Fun√ß√£o principal para avalia√ß√£o
    """
    evaluator = LiggaModelEvaluator()
    
    try:
        results = evaluator.generate_report()
        
        # Resumo final
        print("\n" + "="*60)
        print("RESUMO DA AVALIA√á√ÉO")
        print("="*60)
        print(f"‚úÖ Modelo avaliado com sucesso!")
        print(f"üìä Silhouette Score: {results['silhouette_score']:.4f}")
        print(f"üéØ Consist√™ncia: {results['consistency']:.1f}%")
        print(f"üìÅ Relat√≥rios salvos em: {REPORTS_DIR}/")
        
        # Recomenda√ß√µes
        print(f"\nüí° RECOMENDA√á√ïES:")
        if results['silhouette_score'] > 0.3:
            print("  ‚úÖ Qualidade de clustering: BOA")
        elif results['silhouette_score'] > 0.1:
            print("  ‚ö†Ô∏è  Qualidade de clustering: MODERADA")
        else:
            print("  ‚ùå Qualidade de clustering: BAIXA - Considere ajustar par√¢metros")
        
        if results['consistency'] > 90:
            print("  ‚úÖ Estabilidade do modelo: ALTA")
        elif results['consistency'] > 70:
            print("  ‚ö†Ô∏è  Estabilidade do modelo: MODERADA")
        else:
            print("  ‚ùå Estabilidade do modelo: BAIXA - Considere retreinar")
        
        return results
        
    except Exception as e:
        logging.error(f"Erro na avalia√ß√£o: {e}")
        raise e

if __name__ == "__main__":
    main()
